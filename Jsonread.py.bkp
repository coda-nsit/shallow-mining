import json
import pandas
import numpy
import re
import time

with open('diabetes_30pages.json', 'r') as f:
     data = json.load(f)

with open('diabetes_replies.json', 'r') as f1:
    replies = json.load(f1)

file = open("myfile.txt", "w")
reply = ""
datastring = ""
replyText =" "
for i in range (0, len(data)):
    try:
        # print(data[i]['symptom'])
        datastring = (str(data[i]['title']).strip("[]").strip("''") +" "+ str(data[i]['tags']).strip("[]").strip("''")+ " " +str(data[i]['threadBody']).strip("[]").strip("''"))
        id = str(data[i]['title']).strip("[]").strip("''")

        for j in range(0, len(replies)):
            try:
                reply = (str(replies[j]['threadId']).strip("[]").strip("''"))
                if reply == id:
                      replyText = replyText + " " + (str(replies[j]['replyText']).strip("[]").strip("''"))
            except:
                continue

        file.write(datastring + "" + replyText + "\n")
    except:
        continue

from nltk.stem import PorterStemmer
from nltk.tokenize import word_tokenize
ps = PorterStemmer()

# find the stems of the symptoms
symptomFile = open("symptoms.txt")
lines = symptomFile.readlines()
syms = []
for line in lines:
    for word in line.split():
        syms.append(word)
symptomStems = list(set([ps.stem(w) for w in syms]))

# find the stems of the data
length = len(syms)
fh = open("myfile.txt")
lines = fh.readlines()
finalCount = list()

# for every symptom
for i in range(0, len(symptomStems)):
    count = list()
    startTime = time.time()
    # for every thread
    for j in range(0, len(lines)):
        # clean the words
        # lower case
        words = [w.lower() for w in lines[j].split(" ")]
        # filter out words with digits
        words = [w for w in words if not w.isdigit()]
        # replace punctuations
        words = [re.sub("[!@#$+%*:()'-]*&nbsp;*", '', word) for word in words]
        # check if the symptom stem exists in the line
        lineStem = list(set([ps.stem(w) for w in words]))
        if symptomStems[i] in lineStem:
            count.append(1)
        else:
            count.append(0)
    print("--- %s seconds ---" % (time.time() - startTime))
    finalCount.append(count)
    print("*****")
    print(finalCount)
    print("#####")


symEnc = numpy.array(finalCount)
print(symEnc)
encSym = numpy.transpose(symEnc)

symSym = numpy.matmul(symEnc, encSym)
print(symSym)

I = pandas.Index(syms, name="rows")
C = pandas.Index(syms, name="columns")

file1 = open("output.txt", "w")
df = pandas.DataFrame(symSym,index=I, columns=C)
print(df)
for i in range(0, length):
    df = df.sort_values(by = syms[i], axis=1,ascending= False)
    file1.write(syms[i] + str(df.columns.values.tolist()) + "\n")
print(df)
df.to_csv("symSym.csv")

